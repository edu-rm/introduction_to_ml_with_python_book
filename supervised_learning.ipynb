{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "supervised_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlKZ4yTeVnbwyIWLKD/srI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "30KccwLfmhl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SUPERVISED LEARNING\n",
        "\n",
        "# Sempre que queremos prever um resultado de um input, e temos exemplos de pares \n",
        "# de input e output\n",
        "\n",
        "# Objetivo: fazer previsões através de dados que jamais foram visto antes.\n",
        "# Quase sempre requer esforço humano para construir o dataset, depois automatiza\n",
        "# e quase sempre acelera uma tarefa trabalhosa e inviável.\n",
        "\n",
        "# CLASSIFICATION AND REGRESSION (2 principais tipos de aprendizado supervisionado)\n",
        "\n",
        "# CLASSIFICATION: fazer previsões de classes (uma lista de possibilidades pré definidas)\n",
        "# - Binary classification (yes/no) Ex: Se um email é spam ou não\n",
        "# - Multiclass classification Ex: Iris species, a linguagem de um site baseado no texto\n",
        "\n",
        "# REGRESSION: fazer previsões de números, inteiros ou reais. \n",
        "# Ex: prever o salário anual de uma pesso baseando-se no nível de educação, idade\n",
        "# Ex: Rendimento de um fazenda de milho baseando-se no clima, produções anteriores\n",
        "# e número de funcionários.\n",
        "\n",
        "# Regression sempre possúi continuidade na saída, 10000, 10001 ...\n",
        "\n",
        "\n",
        "# GENERALIZATION, OVERFITTING and UNDERFITTING\n",
        "\n",
        "# No aprendizado supervisionado, queremos criar um modelo que seja treinado pelo \n",
        "# set de treino e seja capaz de fazer previsões de dados desconhecidos, mas que \n",
        "# possuem a mesma características.\n",
        "\n",
        "# Ele faz previsões precisas a partir de dados desconhecidos?\n",
        "# Se sim ele é capaz de generalizar o set de treino para o set de teste.\n",
        "# precisamos de um modelo que seja ao máximo preciso\n",
        "\n",
        "# Conjuntos de dados muito complexos e/ou modelos com pouca quantidade de dados\n",
        "# não terão uma boa accuracy.\n",
        "\n",
        "# É necessário sempre construir modelos mais na sua forma mais simples possível.\n",
        "# Quando um modelo é criado muito complexo para a quantidades de dados que temos \n",
        "# chama-se overfitting\n",
        "\n",
        "# OVERFITTING: Quando há a construção de um modelo que \"está muito\" próximo as \n",
        "# peculiaridades do set de treino, e se esse modelo funciona muito bem no set de \n",
        "# treino mas não nos dados de uma forma geral (generalization).\n",
        "\n",
        "# UNDERFITTING: quando um modelo é muito simples. Ex: \"Todos os que possuem casa\n",
        "# compram um barco\", esse modelo não está considerando variáveis suficientes\n",
        "# então se sairá mal até no set de treino.\n",
        "\n",
        "# Quanto mais complexidade, mais preciso será. Mas se for complexo demais, fi-\n",
        "# cando muito focado em CADA data point ele se sairá mal (Decor), ou seja não \n",
        "# generalizará bem com novos dados\n",
        "\n",
        "# O ponto entre esses dois aspectos é onde permitirá a construção de um modelo\n",
        "# com a melhor performance de generalização."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}